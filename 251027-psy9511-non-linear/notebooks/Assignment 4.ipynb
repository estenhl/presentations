{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80a3626-9d5a-49de-86c3-235082aeae75",
   "metadata": {},
   "source": [
    "#### Assignment 0.1: Download the heart disease dataset from https://www.statlearning.com/s/Heart.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2dc70d-761c-4bd9-97a2-a187a3ba05a3",
   "metadata": {},
   "source": [
    "#### Assignment 0.2: Load the dataset and drop all variables except the predictors Age, Sex, ChestPain, RestBP, Chol, and the target variable AHD. Drop all rows containing a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05205f17-80ea-4933-a0f9-6b1c22ba7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://www.statlearning.com/s/Heart.csv')\n",
    "predictors = ['Age', 'Sex', 'ChestPain', 'RestBP', 'Chol']\n",
    "target = 'AHD'\n",
    "\n",
    "df = df[predictors + [target]]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcbdb0-1b50-444d-9588-28b97b5ffa34",
   "metadata": {},
   "source": [
    "#### Assignment 0.3: Onehot encode the variable ChestPain. This means that where you before had a single column with one of four values ['typical', 'asymptomatic', 'nonanginal', 'nontypical'], you will now have four binary columns (their names don't matter), akin to 'ChestPain_typical' 'ChestPain_asymptomatic', 'ChestPain_nonanginal', 'ChestPain_nontypical'. A row that before had ChestPain='typical' will now have ChestPain_typical=1 and the other three columns set to 0, ChestPain='asymptomatic' will have ChestPain_asymptomatic=1 and the other three set to 0, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f806297-f548-468b-a87f-d150f06ad72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['ChestPain'])\n",
    "\n",
    "predictors.remove('ChestPain')\n",
    "predictors.extend([col for col in df.columns if col.startswith('ChestPain')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00618e-4444-457f-ae66-95cb618cc33a",
   "metadata": {},
   "source": [
    "#### Assignment 0.4: Binary encode the target variable AHD such that 'No'=0 and 'Yes'=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757f6684-42d8-4494-8b55-ccc7e8370255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AHD'] = df['AHD'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae9cb1-8a51-4c60-a811-c7b45d90707f",
   "metadata": {},
   "source": [
    "#### Assignment 1.1: Write a function \"stratified_split\" that takes three arguments: A dataframe, a number of folds, and a list of variables to stratify by. The function should return a list of dataframes, one for each fold, where the dataframes are stratified by the variables in the list. Test that the function works by splitting the dataset into two folds based on 'AHD', 'Age' and 'RestBP' and print the size of each fold, the counts of 0s and 1s in AHD, and the mean of each of 'Age' and 'RestBP' (all these should be printed individually per fold). Ensure that the function does not modify the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1aabfd-e972-4271-a301-d838f83a2db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (n=152)\n",
      "AHD: Counter({0: 82, 1: 70})\n",
      "Age: 54.36\n",
      "RestBP: 132.20\n",
      "Fold 1 (n=151)\n",
      "AHD: Counter({0: 82, 1: 69})\n",
      "Age: 54.52\n",
      "RestBP: 131.18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def stratified_split(df: pd.DataFrame, num_folds: int, variables: List[str]):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(variables)\n",
    "    df['fold'] = np.arange(len(df)) % num_folds\n",
    "\n",
    "    return [df[df['fold'] == fold].drop(columns=['fold']) for fold in np.arange(num_folds)]\n",
    "\n",
    "folds = stratified_split(df, 2, ['AHD', 'Age', 'RestBP'])\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f'Fold {i} (n={len(fold)})')\n",
    "    print(f'AHD: {Counter(fold[\"AHD\"])}')\n",
    "    print(f'Age: {np.mean(fold[\"Age\"]):.2f}')\n",
    "    print(f'RestBP: {np.mean(fold[\"RestBP\"]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372db2e-c67b-4127-b530-89e475f16e58",
   "metadata": {},
   "source": [
    "#### Assignment 1.2: Write a function 'fit_and_predict' that takes 4 arguments: A training set, a validation set, a list of predictors, and a target variable. The function should fit a logistic regression model to the training set using the predictors and target variable, and return the predictions of the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dd23ae-f716-466c-aadb-1a1841b07776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_and_predict(\n",
    "    train: pd.DataFrame, \n",
    "    validation: pd.DataFrame, \n",
    "    predictors: List[str], \n",
    "    target: str\n",
    ") -> np.ndarray:\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train[predictors], train[target])\n",
    "\n",
    "    return model.predict_proba(validation[predictors])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84777be-0060-4f05-b17a-882d40f7ef8b",
   "metadata": {},
   "source": [
    "#### Assignment 1.3: Write a function 'fit_and_predict_standardized' that takes 5 arguments: A training set, a validation set, a list of predictors, a target variable, and a list of variables to standardize. Using a loop (or a scaler), the function should z-score standardize the given variables in both the training set and the validation set based on the mean and standard deviation in the training set. Then, the function should call the 'fit_and_predict' function and return its result. Ensure that the function does not modify the original dataframes. Test the function using the train and validation set from above (e.g. the two folds from the split), while standardizing the 'Age', 'RestBP' and 'Chol' variables (as mentioned above, the target should be AHD, and you should also include the remaining predictors: 'Sex' and the ChestPain-variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1329de50-11a2-4b3b-9c8b-d19d89dc749c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24580942, 0.10301595, 0.04318178, 0.19265105, 0.05521626,\n",
       "       0.35005167, 0.12335629, 0.04871613, 0.03574997, 0.20508148,\n",
       "       0.26053605, 0.13650888, 0.21607723, 0.38691392, 0.63428011,\n",
       "       0.21666342, 0.05742623, 0.15114677, 0.21690386, 0.16463146,\n",
       "       0.64549472, 0.66232289, 0.04653685, 0.147312  , 0.37418151,\n",
       "       0.68481353, 0.27261254, 0.25993081, 0.1947186 , 0.3937794 ,\n",
       "       0.36757399, 0.05514858, 0.24402256, 0.27384063, 0.45940217,\n",
       "       0.0929065 , 0.76984209, 0.46038522, 0.23011678, 0.10416688,\n",
       "       0.52227398, 0.10213225, 0.44635117, 0.46600833, 0.21257989,\n",
       "       0.09340648, 0.3266818 , 0.10975396, 0.37868051, 0.25900628,\n",
       "       0.07960065, 0.51744639, 0.27241878, 0.78507658, 0.49181328,\n",
       "       0.82553098, 0.42673238, 0.33914456, 0.28546738, 0.41136269,\n",
       "       0.83246662, 0.32374632, 0.66724015, 0.13552456, 0.46893256,\n",
       "       0.33775133, 0.57526899, 0.12385073, 0.60020893, 0.58881848,\n",
       "       0.71326235, 0.86031367, 0.2106519 , 0.86117278, 0.35543673,\n",
       "       0.58541456, 0.22401402, 0.19203109, 0.74861786, 0.20078142,\n",
       "       0.19821053, 0.30300452, 0.55570007, 0.59704276, 0.67583962,\n",
       "       0.66182467, 0.31812618, 0.64586669, 0.66740132, 0.70793596,\n",
       "       0.71527688, 0.22589195, 0.17023055, 0.72382156, 0.26855111,\n",
       "       0.77039921, 0.41636278, 0.76740081, 0.75977057, 0.76493598,\n",
       "       0.7918355 , 0.75639476, 0.76950355, 0.35788333, 0.78907236,\n",
       "       0.82941671, 0.79443489, 0.79928434, 0.48137565, 0.77656926,\n",
       "       0.37268089, 0.08485971, 0.83316993, 0.3255086 , 0.7775858 ,\n",
       "       0.79243957, 0.80845985, 0.81469172, 0.09077241, 0.84077842,\n",
       "       0.80035074, 0.58554259, 0.63212672, 0.86612146, 0.6191749 ,\n",
       "       0.82674082, 0.83301271, 0.84256496, 0.58222138, 0.82820097,\n",
       "       0.6086224 , 0.85357099, 0.86205804, 0.31679666, 0.58016557,\n",
       "       0.60925457, 0.5326611 , 0.85413283, 0.86731161, 0.85052882,\n",
       "       0.47924201, 0.84636994, 0.66193946, 0.85696873, 0.71150428,\n",
       "       0.87053439, 0.87424117, 0.90248383, 0.621122  , 0.89254122,\n",
       "       0.60658052])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fit_and_predict_standardized(\n",
    "    train: pd.DataFrame, \n",
    "    validation: pd.DataFrame, \n",
    "    predictors: List[str],\n",
    "    target: str,\n",
    "    standardize: List[str]\n",
    ") -> np.ndarray:\n",
    "    train = train.copy()\n",
    "    validation = validation.copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train[standardize] = scaler.fit_transform(train[standardize])\n",
    "    validation[standardize] = scaler.transform(validation[standardize])\n",
    "\n",
    "    return fit_and_predict(train, validation, predictors, target)\n",
    "\n",
    "fit_and_predict_standardized(folds[0], folds[1], predictors, target, ['Age', 'RestBP', 'Chol'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79193275-cf1f-4184-b11d-b3ec3fdddbcf",
   "metadata": {},
   "source": [
    "#### Assignment 1.4: Write a function 'fit_and_compute_auc' that takes 5 arguments: A training set, a validation set, a list of predictors, a target variable, and a list of variables to standardize. The function should call the 'fit_and_predict_standardized' function to retrieve out-of-sample predictions for the validation set. Based on these and the ground truth labels in the validation set, it should compute and return the AUC. Test the function using the train and test set from above, while standardizing the 'Age', 'RestBP' and 'Chol' variables (and including the remaining predictors). Print the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f498e1a8-0864-4e25-aeae-f5f887068d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def fit_and_compute_auc(\n",
    "    train: pd.DataFrame, \n",
    "    validation: pd.DataFrame, \n",
    "    predictors: List[str],\n",
    "    target: str,\n",
    "    standardize: List[str]\n",
    "):\n",
    "    predictions = fit_and_predict_standardized(train, validation, predictors, target, standardize)\n",
    "\n",
    "    return roc_auc_score(validation[target], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950790f3-5b65-4a49-a71c-c37a5b85a1ec",
   "metadata": {},
   "source": [
    "#### Assignment 2: Use the 'stratified_split' function to split the dataset into 10 folds, stratified on variables you find reasonable. For each fold, use the 'fit_and_compute_auc' function to compute the AUC of the model on the held-out validation set. Print the mean and standard deviation of the AUCs across the 10 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861794b7-13f1-4898-8a2f-fd4db2453bc7",
   "metadata": {},
   "source": [
    "folds = stratified_split(df, 10, ['AHD', 'Age'])\n",
    "\n",
    "aucs = [\n",
    "    fit_and_compute_auc(\n",
    "        pd.concat([fold for j, fold in enumerate(folds) if j != i]),\n",
    "        folds[i],\n",
    "        predictors,\n",
    "        target,\n",
    "        ['Age', 'RestBP', 'Chol']\n",
    "    ) for i in range(len(folds))\n",
    "]\n",
    "\n",
    "print(f'AUC: {np.mean(aucs):.2f}+/-{np.std(aucs):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f616b-b410-4979-a380-037cda7ef3d0",
   "metadata": {},
   "source": [
    "#### Assignment 3: For 100 iterations, create a bootstrap sample by sampling with replacement from the full dataset until you have a training set equal in size to 80% of the original data. Use the observations not included in the bootstrap sample as the validation set for that iteration.. Fit models and calculate AUCs for each iteration. Print the mean and standard deviation of the AUCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8e3da14-a44c-40b1-941f-af0d1d9c3b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 275.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.83+/-0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "aucs = []\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    train = df.sample(frac=0.8, replace=True)\n",
    "    validation = df[~df.index.isin(train.index)]\n",
    "    aucs.append(\n",
    "        fit_and_compute_auc(\n",
    "            train,\n",
    "            validation,\n",
    "            predictors,\n",
    "            target,\n",
    "            ['Age', 'RestBP', 'Chol']\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f'AUC: {np.mean(aucs):.2f}+/-{np.std(aucs):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e6182-6a4f-44b9-8bb7-6b5521337851",
   "metadata": {},
   "source": [
    "#### Assignment 4.1:  List some benefits of wrapping code in functions rather than copying and pasting it multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3335b-5e4c-48d1-b50a-7bfbe05e38c2",
   "metadata": {},
   "source": [
    "- Code becomes more reusable\n",
    "- Bugs have to be fixed in a single place\n",
    "- It is often easier to reason about the high-level functioning of code in terms of abstract chunks (i.e. functions) as opposed to individual lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3b518-6804-4f1d-adda-7f493cd0aec0",
   "metadata": {},
   "source": [
    "#### Assignment 4.2:  Explain three classification metrics and their benefits and drawbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027d308-c7a6-4355-b096-45b91e09809a",
   "metadata": {},
   "source": [
    "- Accuracy: Measures the proportion of correct predictions across a dataset. Very intuitive to interpret, but can be misleading in the case of imbalanced classes.\n",
    "- Area under the ROC-curve: Measures the trade-off between true positive rate and false positive rate and several classification thresholds. Gives a more comprehensive view of model performance than many metrics that rely on singular classification thresholds. However, before using a model in practice, a threshold often has to be set. Can be misleading in cases of class imbalance where the specific types of misclassification matter.\n",
    "- Area under the precision-recall curve: Similar to AUROC, but measures the trade-off between precision and recall instead. Can be more informative in cases of severe class imbalance, especially when the negative class dominates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24279aa-605d-47c7-8471-b872c78ff975",
   "metadata": {},
   "source": [
    "#### Assignment 4.3:  Write a couple of sentences comparing the three methods (train/validation, cross-validation, bootstrap) above as approaches to quantify model performance. Which one yielded the best results? Which one would you expect to yield the best results? Can you mention some theoretical benefits and drawbacks with each? Even if you didn't do the optional bootstrap exercise you should reflect on this as an approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d562c7-08ab-43b6-abc8-a3dd64cb9867",
   "metadata": {},
   "source": [
    "- Train/validation: Relies on a single data split, reserving a portion of the data for training and another portion for validation. Provides an unbiased measure of model performance conditioned on the specific split. In practice, this means that we have to assume the measure will be highly variable, depending on exactly what data ends up where.\n",
    "- Cross-validation: Splits the data into K folds, and runs several training iterations, each reserving a single fold for validation. Provides several model performances (one per fold), which can be useful to get a more comprehensive view of the model performance and its expected variance.\n",
    "- Bootstrap: If we use the bootstrap approach described here (often called either repeated hold-out or monte-carlo cross-validation) we repeatedly sample a portion of the dataset for training and use the remaining samples for validation. If we, as here, sample 80% of the dataset for training with replacement, this would mean that effectively less data is used for training (due to the resampling) and more for testing. In sum, we would expect this to give a slightly lower mean performance and a slightly lower variance among the observed performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5607b1-08ba-487c-9c26-1278af1758a1",
   "metadata": {},
   "source": [
    "#### Assignment 4.4: Why do we stratify the dataset before splitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6fe7f-b65b-49ef-a45d-135a89ec422b",
   "metadata": {},
   "source": [
    "We stratify the data prior to splitting to ensure all of our folds are approximately representative with regards to a few key variables. In addition to ensuring that our models are more probable to generalize to new samples, this also typically mean that we see better out-of-sample performance in held-out data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254fbbc-1f28-423d-8926-2fb569d617d1",
   "metadata": {},
   "source": [
    "#### Assignment 4.5: What other use cases can you think of for the bootstrap method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4773cc-affd-4f8a-8a98-36e797519ac6",
   "metadata": {},
   "source": [
    "The bootstrap is most commonly used to provide confidence intervals for parameter estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
